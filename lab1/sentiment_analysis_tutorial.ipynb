{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model  import PassiveAggressiveClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Task: Beer Sentiment Analysis\n",
    "\n",
    "Given long and detailed beer reviews, we want to predict if the reviewed ranked it as an bad, okay or good.\n",
    "\n",
    "\n",
    "## Step 1: Preprocessing the data\n",
    "To start off, we're going to load the data from some pickle files and do some simple preprocessing. We'll throw away non-alphanumeric characters and lowercase everything.\n",
    "\n",
    "i.e\n",
    "```\"Best Beer ever!!!\" -> \"best beer ever\"```\n",
    "\n",
    "The sanity check the data, we'll look at a few examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/beer/overall_train.p\"\n",
    "dev_path   = \"data/beer/overall_dev.p\"\n",
    "test_path  = \"data/beer/overall_test.p\"\n",
    "\n",
    "train_set =  pickle.load(open(train_path, 'rb'))\n",
    "dev_set =  pickle.load(open(dev_path, 'rb'))\n",
    "test_set =  pickle.load(open(test_path, 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(data):\n",
    "    for indx, sample in enumerate(data):\n",
    "        text, label = sample['text'], sample['y']\n",
    "        text = re.sub('\\W+', ' ', text).lower().strip()\n",
    "        data[indx] = text, label\n",
    "    return data\n",
    "\n",
    "train_set = preprocess_data(train_set)\n",
    "dev_set = preprocess_data(dev_set)\n",
    "test_set =  preprocess_data(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train: 20000\n",
      "Num Dev: 5000\n",
      "Num Test: 5000\n",
      "Example Tweets:\n",
      "('a clear and very pale yellow color poured lt 1 finger fizzy white head very little lacing decanted continually s sweet fruity scent mixed with notes of corn and rice there is a light spicy hops finish but it s very light t strong malty start of sweet fruits such as apples there is a nice blend of corn that does n t bring a bad flavor there is a spicy flavor of hops and medicine the medicinal taste is n t bad at all but adds a little depth to this light adjunct beer m smooth and sweet at first then turns a bit spicy and fizzy finishes very clean crisp and quite refreshing d good better than most light lager', 2)\n",
      "\n",
      "('ruby redbird served in new belgium globe glass a pours clear pale amber with a fizzy head that fizzles out immediately very good effervescence s smells like i cracked open a vernor s beyond the ginger ale i find no additional aromas t no beer in taste either grapefruit peels to ginger ale then medium bitterness and something like stewed vegetables bone dry finish is thin and faded ginger and grapefruit bitterness m light body and bright carbonation fizzy and crisp mouthfeel o after a couple of drinks of ruby redbird i thought to myself are texans really drinking this shit honestly the smell of freshly grated is such a tease when you follow it up with this beer gimmicky one trick pony', 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Num Train: {}\".format(len(train_set)))\n",
    "print(\"Num Dev: {}\".format(len(dev_set)))\n",
    "print(\"Num Test: {}\".format(len(test_set)))\n",
    "print(\"Example Tweets:\")\n",
    "print(train_set[0])\n",
    "print()\n",
    "print(train_set[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering \n",
    "\n",
    "How do we represent a review? We're going to use a simple bag of words representation. Meaning we'll represent each review as a vector, and the whole set of reviews as a large matrix.\n",
    "\n",
    "For example, consider our vocabulary is ```[best, ever, beer, cat, good, dog]```.\n",
    "The bag of words representation for:\n",
    "```\"best beer ever\"``` is ```[1, 1, 1, 0, 0, 0]```\n",
    "Where one indicates that the vocab words did appear and 0 indicates the words that did not. S\n",
    "\n",
    "In python, we can do this very easily with ```sklearn.feature_extraction.text.CountVectorizer```\n",
    "\n",
    "<img src=\"vectorizer.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract tweets and labels into 2 lists\n",
    "trainText = [t[0] for t in train_set]\n",
    "trainY = [t[1] for t in train_set]\n",
    "\n",
    "devText = [t[0] for t in dev_set]\n",
    "devY = [t[1] for t in dev_set]\n",
    "\n",
    "\n",
    "testText = [t[0] for t in test_set]\n",
    "testY = [t[1] for t in test_set]\n",
    "\n",
    "# Set that word has to appear at least 5 times to be in vocab\n",
    "min_df = 5\n",
    "max_features = 1000\n",
    "countVec = CountVectorizer(min_df = min_df, max_features = max_features )\n",
    "# Learn vocabulary from train set\n",
    "countVec.fit(trainText)\n",
    "\n",
    "# Transform list of review to matrix of bag-of-word vectors\n",
    "trainX = countVec.transform(trainText)\n",
    "devX = countVec.transform(devText)\n",
    "testX = countVec.transform(testText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train X (20000, 1000)\n",
      "\n",
      "Sample of the vocab:\n",
      " ['enjoyed' 'good' 'fruit' 'care' 'use' 'feel' 'note' 'cherries' 'pepper'\n",
      " 'everything' 'high' 'sits' 'enjoyed' 'pils' 'seems' 'beautiful' 'smokey'\n",
      " 'while' 'do' 'found']\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train X {}\\n\".format(trainX.shape))\n",
    "print(\"Sample of the vocab:\\n {}\".format(np.random.choice(countVec.get_feature_names(), 20)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Pick a model and experiment\n",
    "\n",
    "Here we'll explore various types of linear models, namely Logistic Regression, Passive Aggressive, and Perceptron. It's very straight-forward\n",
    "to fit a new classifier and get preliminary results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "passAgg    = PassiveAggressiveClassifier()\n",
    "perceptron = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train: 0.7215\n",
      "Logistic Regression Dev: 0.6866\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "lr.fit(trainX, trainY)\n",
    "\n",
    "\n",
    "print(\"Logistic Regression Train:\", lr.score(trainX, trainY))\n",
    "print(\"Logistic Regression Dev:\", lr.score(devX, devY))\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passive Aggressive Train: 0.6755\n",
      "Passive Aggressive Dev: 0.6294\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "passAgg.fit(trainX, trainY) \n",
    "print(\"Passive Aggressive Train:\", passAgg.score(trainX, trainY))\n",
    "print(\"Passive Aggressive Dev:\", passAgg.score(devX, devY))\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Train: 0.6175\n",
      "Perceptron Dev: 0.5904\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "perceptron.fit(trainX, trainY) \n",
    "print(\"Perceptron Train:\", perceptron.score(trainX, trainY))\n",
    "print(\"Perceptron Dev:\", perceptron.score(devX, devY))\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analysis, Debugging the Model\n",
    "To understand how to make the model better, it's important understand what the model is learning, and what it's getting wrong.\n",
    "\n",
    "To do this, we can inspect the highest weighted features of our best LR model and look at some examples the model got wrong on the development set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train: 0.73415\n",
      "Logistic Regression Dev: 0.6782\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(trainX, trainY)\n",
    "print(\"Logistic Regression Train:\", lr.score(trainX, trainY))\n",
    "print(\"Logistic Regression Dev:\", lr.score(devX, devY))\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intepreting LR\n",
      "Top weighted features for label 0:\n",
      " \n",
      " [('poor', 0.6536027130614585), ('sips', 0.6823759395892621), ('rest', 0.7083852080854629), ('qualities', 0.7920728750592017), ('disappointed', 0.8111794793649244), ('clarity', 0.8535110675245677), ('terrible', 0.8921344193706889), ('unpleasant', 0.9025258573798056), ('awful', 1.4219141470015884), ('drain', 2.6212975191465695)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label 1:\n",
      " \n",
      " [('chewy', 0.4059729562340314), ('warming', 0.41885905106964993), ('silky', 0.43718138460235706), ('heavy', 0.4395226317978089), ('viscous', 0.4571915991167313), ('warmth', 0.46488942889181367), ('oil', 0.4842823050826067), ('filling', 0.5002173093436909), ('sipping', 0.6180110468421688), ('sipper', 1.013004502555345)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label 2:\n",
      " \n",
      " [('drinks', 0.6248636435439002), ('summer', 0.667920328401007), ('thirst', 0.753415689183526), ('settles', 0.7771403020805547), ('easily', 0.8312511645437842), ('session', 0.8588465533673536), ('refreshing', 0.9197048115724349), ('drinkable', 1.3245358949102668), ('sessionable', 1.3536508960015894), ('easy', 1.382721054212072)]\n",
      " -- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Intepreting LR\")\n",
    "for label in range(3):\n",
    "    coefs = lr.coef_[label]\n",
    "    vocab = np.array(countVec.get_feature_names())\n",
    "    num_features = 10\n",
    "\n",
    "    top = np.argpartition(coefs, -num_features)[-num_features:]\n",
    "    # Sort top\n",
    "    top = top[np.argsort(coefs[top])]\n",
    "    s_coef = coefs[top]\n",
    "    scored_vocab = list(zip(vocab[top], s_coef))\n",
    "    print(\"Top weighted features for label {}:\\n \\n {}\\n -- \\n\".format(label, scored_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random dev error: \n",
      " ['Review: \\n poured from a growler into a tulip pint glass dry hopped with amarillo and centennial hops according to the menu at the stone company store a hazy light amber color with one finger of persistent white foam head moderate lacing remains on the glass s hops dominate but do not smother with floral and juicy citrus qualities malt is soft and toasty subordinate but not left out while carbonic acid enhances the citric side of the hops and also imparts a crisp edge t begins off dry with variable moderate to pungent hop aromatics of pineapple and savory cooking herbs moderate acidity is also present remaining within acceptable bounds and adding to early brightness the middle and finish are more malt focused yet the footprint of the grain is feather light and bready bitterness is subdued for the style lingering at the edges of the tongue and generally staying out of the way m medium viscosity slightly sticky on the palate with moderate carbonation d o freshness is the imperative winning element present in this beer setting it apart from the standard formula in a fashion that has nothing to do with the brewed on date the hop flavors are both titillating and palate filling at their most intense yet the perceived intensity varies with each sip and the different aromatic qualities seem not to be entirely copacetic still the finished product is a minor wonder to behold probably comparable to any other american ipa with similar limited availability \\n Predicted: 1 \\n Correct: 2 \\n ---'] \n",
      " \n",
      " ['Review: \\n ok it s a lite beer we all know that now for what it is it s just that a watery lite beer that can be thrown down in mass quantities you do n t ave to think about it to drink it i will say that i did drink this beer alot back in the day and as long as it s ice cold it s ok again for what it is high drinkability as it has no taste now i drink my sa beers i ve matured in some ways cheers \\n Predicted: 2 \\n Correct: 1 \\n ---'] \n",
      " \n",
      "['Review: \\n poured with little head or lace and was a slightly cloudy amber and smelled of malty goodness a hint of alcohol and some of the hops this smelled like a bock mouth washed with a little old water flavor slightly musty and washed with a sweetness that was like a mild maple syrup so this was a malty lager average actually the bite from the hops and the rounded malt toasted a bit but there was a hole in the middle the wheat toasted makes a good flavor but it does not follow through okay for what it s worth but there are lots of better out there would n t get again \\n Predicted: 2 \\n Correct: 0 \\n ---']\n"
     ]
    }
   ],
   "source": [
    "## Find erronous dev errors\n",
    "devPred = lr.predict(devX)\n",
    "errors = []\n",
    "for indx in range(len(devText)):\n",
    "    if devPred[indx] != devY[indx]:\n",
    "        error = \"Review: \\n {} \\n Predicted: {} \\n Correct: {} \\n ---\".format(\n",
    "            devText[indx],\n",
    "            devPred[indx],\n",
    "            devY[indx])\n",
    "        errors.append(error)\n",
    "\n",
    "np.random.seed(1)\n",
    "print(\"Random dev error: \\n {} \\n \\n {} \\n \\n{}\".format(\n",
    "        np.random.choice(errors,1),\n",
    "        np.random.choice(errors,1),\n",
    "        np.random.choice(errors,1))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Play with regularization\n",
    "\n",
    "We can see that LogisticRegression so far works the best so far, but it is greatly over fitting. Meaning that it does much better on train than development. A common strategy to dealing with this is adding an extra penalty for model complexity, like the square sum of the model weights. We call this idea regularization. \n",
    "\n",
    "In sklearn, it is very easy to test out various regularization amounts and tune the model. The smaller the parameter `C`, the stronger the regularization cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train: 0.73455\n",
      "Logistic Regression Dev: 0.6784\n",
      "--\n",
      "Logistic Regression Train: 0.7331\n",
      "Logistic Regression Dev: 0.679\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=.5)\n",
    "lr.fit(trainX, trainY)\n",
    "\n",
    "\n",
    "print(\"Logistic Regression Train:\", lr.score(trainX, trainY))\n",
    "print(\"Logistic Regression Dev:\", lr.score(devX, devY))\n",
    "print(\"--\")\n",
    "\n",
    "lr = LogisticRegression(C=.1)\n",
    "lr.fit(trainX, trainY)\n",
    "\n",
    "\n",
    "print(\"Logistic Regression Train:\", lr.score(trainX, trainY))\n",
    "print(\"Logistic Regression Dev:\", lr.score(devX, devY))\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train: 0.7215\n",
      "Logistic Regression Dev: 0.6866\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=.01)\n",
    "lr.fit(trainX, trainY)\n",
    "\n",
    "\n",
    "print(\"Logistic Regression Train:\", lr.score(trainX, trainY))\n",
    "print(\"Logistic Regression Dev:\", lr.score(devX, devY))\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Adding in Ngrams\n",
    "\n",
    "How does our model distinguish between the sentiment phrase that says:\n",
    "```\"great flavor and too bad there isn't more.\"```\n",
    "versus\n",
    "```\"bad flavor and too great there isn't more.\"```\n",
    "\n",
    "In our bag of words model, both have the same vector. In order to capture some of these ordering depency, we generalize the bag-of-words model to take \"n-grams\" of words that occur in the training set. a \"bi-gram\" is a pair of words, \"tri-gram\" triple, etc.\n",
    "\n",
    "Let see how this imporves our model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set that word has to appear at least 5 times to be in vocab\n",
    "min_df = 5\n",
    "ngram_range = (1,3)\n",
    "max_features = 5000\n",
    "countVecNgram = CountVectorizer(min_df = min_df, ngram_range = ngram_range, max_features=max_features)\n",
    "# Learn vocabulary from train set\n",
    "countVecNgram.fit(trainText)\n",
    "\n",
    "# Transform list of review to matrix of bag-of-word vectors\n",
    "trainXNgram = countVecNgram.transform(trainText)\n",
    "devXNgram = countVecNgram.transform(devText)\n",
    "testXNgram = countVecNgram.transform(testText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Train: 0.88255\n",
      "Logistic Regression Dev: 0.6534\n",
      "--\n",
      "Logistic Regression Train: 0.87305\n",
      "Logistic Regression Dev: 0.6634\n",
      "--\n",
      "Logistic Regression Train: 0.8428\n",
      "Logistic Regression Dev: 0.6864\n",
      "--\n",
      "Logistic Regression Train: 0.77645\n",
      "Logistic Regression Dev: 0.7036\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "lrNgram = LogisticRegression(C=1)\n",
    "lrNgram.fit(trainXNgram, trainY)\n",
    "print(\"Logistic Regression Train:\", lrNgram.score(trainXNgram, trainY))\n",
    "print(\"Logistic Regression Dev:\", lrNgram.score(devXNgram, devY))\n",
    "print(\"--\")\n",
    "\n",
    "lrNgram = LogisticRegression(C=.5)\n",
    "lrNgram.fit(trainXNgram, trainY)\n",
    "print(\"Logistic Regression Train:\", lrNgram.score(trainXNgram, trainY))\n",
    "print(\"Logistic Regression Dev:\", lrNgram.score(devXNgram, devY))\n",
    "print(\"--\")\n",
    "\n",
    "lrNgram = LogisticRegression(C=.1)\n",
    "lrNgram.fit(trainXNgram, trainY)\n",
    "print(\"Logistic Regression Train:\", lrNgram.score(trainXNgram, trainY))\n",
    "print(\"Logistic Regression Dev:\", lrNgram.score(devXNgram, devY))\n",
    "print(\"--\")\n",
    "\n",
    "lrNgram = LogisticRegression(C=.01)\n",
    "lrNgram.fit(trainXNgram, trainY)\n",
    "print(\"Logistic Regression Train:\", lrNgram.score(trainXNgram, trainY))\n",
    "print(\"Logistic Regression Dev:\", lrNgram.score(devXNgram, devY))\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Take best model, and report results on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test: 0.7088\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Test:\", lrNgram.score(testXNgram, testY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
