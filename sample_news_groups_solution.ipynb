{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model  import PassiveAggressiveClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Task: News Group Classification\n",
    "\n",
    "Given documents in different news groups (i.e topics):\n",
    "```\n",
    "['alt.atheism',\n",
    " 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x',\n",
    " 'misc.forsale',\n",
    " 'rec.autos',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'sci.crypt',\n",
    " 'sci.electronics',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'soc.religion.christian',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.politics.misc',\n",
    " 'talk.religion.misc']```\n",
    " \n",
    "Train a classifier to predict the topic of a given document. \n",
    "\n",
    "\n",
    "## Step 1: Preprocessing the data\n",
    "To start off, we're going to load the data from sklearn and do some simple preprocessing. We'll remove the headers, footers and quotes in the articles. We'll also do the same preprocessing as before.\n",
    "\n",
    "\n",
    "The sanity check the data, we'll look at a few examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categories = ['alt.atheism',\n",
    " 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x',\n",
    " 'misc.forsale',\n",
    " 'rec.autos',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'sci.crypt',\n",
    " 'sci.electronics',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'soc.religion.christian',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.politics.misc',\n",
    " 'talk.religion.misc']\n",
    "\n",
    "full_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for indx, sample in enumerate(data['data']):\n",
    "        text, label = sample, data['target'][indx]\n",
    "        label_name = data['target_names'][label]\n",
    "        text = re.sub('\\W+', ' ', text).lower().strip()\n",
    "        processed_data.append( (text, label, label_name) )\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "train_set = preprocess_data(full_train)\n",
    "full_test_set = preprocess_data(test)\n",
    "half_indx = len(full_test_set) // 2\n",
    "dev_set = full_test_set[:half_indx]\n",
    "test_set = full_test_set[half_indx:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Train: 11314\n",
      "Num Dev: 3766\n",
      "Num Test: 3766\n",
      "Example Documents:\n",
      "('i was wondering if anyone out there could enlighten me on this car i saw the other day it was a 2 door sports car looked to be from the late 60s early 70s it was called a bricklin the doors were really small in addition the front bumper was separate from the rest of the body this is all i know if anyone can tellme a model name engine specs years of production where this car is made history or whatever info you have on this funky looking car please e mail', 7, 'rec.autos')\n",
      "\n",
      "('a fair number of brave souls who upgraded their si clock oscillator have shared their experiences for this poll please send a brief message detailing your experiences with the procedure top speed attained cpu rated speed add on cards and adapters heat sinks hour of usage per day floppy disk functionality with 800 and 1 4 m floppies are especially requested i will be summarizing in the next two days so please add to the network knowledge base if you have done the clock upgrade and haven t answered this poll thanks', 4, 'comp.sys.mac.hardware')\n"
     ]
    }
   ],
   "source": [
    "print(\"Num Train: {}\".format(len(train_set)))\n",
    "print(\"Num Dev: {}\".format(len(dev_set)))\n",
    "print(\"Num Test: {}\".format(len(test_set)))\n",
    "print(\"Example Documents:\")\n",
    "print(train_set[0])\n",
    "print()\n",
    "print(train_set[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering \n",
    "\n",
    "How do we represent a document? This is up to you!\n",
    "Remeber, you can vary the vocabulary size, choose to put ``ngrams``!\n",
    "\n",
    "Remember, we can do this very easily with ```sklearn.feature_extraction.text.CountVectorizer```\n",
    "\n",
    "<img src=\"vectorizer.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract tweets and labels into 2 lists\n",
    "trainText = [t[0] for t in train_set]\n",
    "trainY = [t[1] for t in train_set]\n",
    "\n",
    "devText = [t[0] for t in dev_set]\n",
    "devY = [t[1] for t in dev_set]\n",
    "\n",
    "\n",
    "testText = [t[0] for t in test_set]\n",
    "testY = [t[1] for t in test_set]\n",
    "\n",
    "min_df = 10\n",
    "max_df = 0.90\n",
    "ngram_range = (1,3)\n",
    "max_features = 10000\n",
    "countVec = CountVectorizer(min_df=min_df, \n",
    "                           max_df=max_df,\n",
    "                           max_features=max_features, \n",
    "                           ngram_range=ngram_range,\n",
    "                           stop_words='english')\n",
    "\n",
    "\n",
    "\n",
    "# Learn vocabulary from train set\n",
    "countVec.fit(trainText)\n",
    "\n",
    "# Transform list of review to matrix of bag-of-word vectors\n",
    "trainX = countVec.transform(trainText)\n",
    "devX = countVec.transform(devText)\n",
    "testX = countVec.transform(testText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train X (11314, 10000)\n",
      "\n",
      "Sample of the vocab:\n",
      " ['06' 'competitive' 'salt lake' 'ax qq' 'wont' 'appreciate help' 'divorce'\n",
      " 'asked' 'vehicles' 'entitled' '171' 'height' '99' 'verified' 'repairs'\n",
      " 'british columbia' 'purchased' 'scenario' 'gaza' '1k']\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train X {}\\n\".format(trainX.shape))\n",
    "print(\"Sample of the vocab:\\n {}\".format(np.random.choice(countVec.get_feature_names(), 20)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Pick a model and experiment\n",
    "\n",
    "Explore various models.\n",
    "\n",
    "I recomment exploring:\n",
    "1) [Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "2) [SVM](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC)\n",
    "\n",
    "And look around the [library](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm) for other options!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model\n",
    "model = LogisticRegression(C=.01, class_weight='balanced',\n",
    "                          penalty='l2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.796623652112427\n",
      "Dev Accuracy: 0.6147105682421667\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY)\n",
    "\n",
    "\n",
    "print(\"Train Accuracy:\", model.score(trainX, trainY))\n",
    "print(\"Dev Accuracy:\", model.score(devX, devY))\n",
    "print(\"--\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analysis, Debugging the Model\n",
    "To understand how to make the model better, it's important understand what the model is learning, and what it's getting wrong.\n",
    "\n",
    "Recall how we did this for Logistic regression. \n",
    "\n",
    "It can be helpful inspect the highest weighted features of the model and look at some examples the model got wrong on the development set. \n",
    "\n",
    "From what you learn, you can go back and change the feature extraction or the regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intepreting The model\n",
      "Top weighted features for label alt.atheism:\n",
      " \n",
      " [('atheists', 0.2508224700706764), ('bobby', 0.251900662476618), ('islam', 0.2614863479822565), ('religion', 0.29313138803917493), ('atheism', 0.3371166518907043)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label comp.graphics:\n",
      " \n",
      " [('points', 0.2329220492610428), ('format', 0.24626965423717934), ('3d', 0.3390495214970012), ('image', 0.3881850248658815), ('graphics', 0.6634338137546953)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label comp.os.ms-windows.misc:\n",
      " \n",
      " [('cica', 0.2329072024274239), ('files', 0.23393640959673792), ('driver', 0.2368856115670537), ('file', 0.25078666667591404), ('windows', 0.8374673986023785)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label comp.sys.ibm.pc.hardware:\n",
      " \n",
      " [('ide', 0.26686977658231464), ('bus', 0.26746340569651283), ('486', 0.26873263214960724), ('monitor', 0.2687903828457623), ('controller', 0.28924167515277377)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label comp.sys.mac.hardware:\n",
      " \n",
      " [('simms', 0.2546933566392113), ('se', 0.2592641280745662), ('quadra', 0.29428575292549836), ('apple', 0.6557807949057544), ('mac', 0.6779908811605838)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label comp.windows.x:\n",
      " \n",
      " [('xterm', 0.26536181459238456), ('widget', 0.34596891151432096), ('motif', 0.4818213622317266), ('server', 0.5102147623378773), ('window', 0.5325079062885739)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label misc.forsale:\n",
      " \n",
      " [('sell', 0.35870160610570173), ('condition', 0.3674872659134913), ('shipping', 0.4124159806656906), ('offer', 0.4796275788724627), ('sale', 0.7129805319092154)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label rec.autos:\n",
      " \n",
      " [('dealer', 0.2499042724583308), ('ford', 0.26070875921233666), ('engine', 0.3091082923704393), ('cars', 0.5506727592523569), ('car', 0.896903194536237)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label rec.motorcycles:\n",
      " \n",
      " [('helmet', 0.32264900981555084), ('ride', 0.3765629300422468), ('bikes', 0.3770564753160294), ('dod', 0.4845195461118918), ('bike', 0.9281135584687642)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label rec.sport.baseball:\n",
      " \n",
      " [('braves', 0.2881646640640587), ('runs', 0.30105857458208135), ('hit', 0.32963298138914177), ('year', 0.35839842624113494), ('baseball', 0.4956531843923658)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label rec.sport.hockey:\n",
      " \n",
      " [('play', 0.3126620083778154), ('nhl', 0.34200981395814634), ('team', 0.37830351717409527), ('game', 0.4110324609603067), ('hockey', 0.6247471610677454)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label sci.crypt:\n",
      " \n",
      " [('chip', 0.2964920833822012), ('nsa', 0.4317884463477918), ('key', 0.43692604324229256), ('encryption', 0.5049213474643688), ('clipper', 0.5150828483661665)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label sci.electronics:\n",
      " \n",
      " [('ground', 0.23834543828658933), ('voltage', 0.2485609948184768), ('current', 0.25578403549243495), ('electronics', 0.32742808127750717), ('circuit', 0.36134328541204686)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label sci.med:\n",
      " \n",
      " [('pain', 0.27098044197604765), ('medical', 0.30057573614470673), ('disease', 0.36344240606648504), ('msg', 0.3842142300244789), ('doctor', 0.3908318175715375)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label sci.space:\n",
      " \n",
      " [('launch', 0.3165557482315943), ('orbit', 0.34610784156121704), ('moon', 0.35433716470462195), ('nasa', 0.3758853556187711), ('space', 0.8675520758555966)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label soc.religion.christian:\n",
      " \n",
      " [('christianity', 0.2461204095060409), ('christ', 0.27157945094046604), ('god', 0.27524172777485517), ('christians', 0.28983042441430806), ('church', 0.40630485858163107)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label talk.politics.guns:\n",
      " \n",
      " [('firearms', 0.28014681243986195), ('fbi', 0.3103946262737739), ('weapons', 0.39783490213890615), ('guns', 0.4616394075638342), ('gun', 0.5938349241767348)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label talk.politics.mideast:\n",
      " \n",
      " [('armenians', 0.2750581596329377), ('arab', 0.31232653478147676), ('jews', 0.39239533548837974), ('israeli', 0.48906444048717634), ('israel', 0.6226661309544831)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label talk.politics.misc:\n",
      " \n",
      " [('men', 0.21485863593616744), ('drugs', 0.2601251370552253), ('government', 0.2616986330462397), ('clinton', 0.2823177481037563), ('tax', 0.3155738826637502)]\n",
      " -- \n",
      "\n",
      "Top weighted features for label talk.religion.misc:\n",
      " \n",
      " [('order', 0.23025563639157587), ('christian', 0.23289793272855538), ('objective', 0.2461322043191628), ('koresh', 0.2508711515145893), ('kent', 0.2511813642780608)]\n",
      " -- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Intepreting The model\")\n",
    "for label in range(20):\n",
    "    coefs = model.coef_[label]\n",
    "    vocab = np.array(countVec.get_feature_names())\n",
    "    num_features = 5\n",
    "\n",
    "    top = np.argpartition(coefs, -num_features)[-num_features:]\n",
    "    # Sort top\n",
    "    top = top[np.argsort(coefs[top])]\n",
    "    s_coef = coefs[top]\n",
    "    scored_vocab = list(zip(vocab[top], s_coef))\n",
    "    print(\"Top weighted features for label {}:\\n \\n {}\\n -- \\n\".format(test['target_names'][label], scored_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random dev error: \n",
      " ['Document: \\n unfortunately roger is now over at r s baseball spewing his expertise i e being a dickhead i guess he is afraid of posting anything here because he knows what to expect \\n Predicted: rec.sport.baseball \\n Correct: rec.sport.hockey \\n ---'] \n",
      " \n",
      " ['Document: \\n date sun 25 apr 1993 10 13 30 gmt from fred rice darice yoyo cc monash edu au the qur an talks about those who take their lusts and worldly desires for their god i think this probably encompasses most atheists fred rice darice yoyo cc monash edu au as well as all the muslim men screwing fourteen year old prostitutes in thailand got a better quote \\n Predicted: sci.space \\n Correct: alt.atheism \\n ---'] \n",
      " \n",
      "['Document: \\n precisely one wonders what unusual strain the boy might be under that could be causing difficulty with his behavior standard practice would be to get a second opinion from a child psychiatrist one would want to rule out the possibility that the bad behavior is not psychiatric illness at all disclaimer i am not a medic but i am a parent \\n Predicted: rec.sport.baseball \\n Correct: sci.med \\n ---']\n"
     ]
    }
   ],
   "source": [
    "## Find erronous dev errors\n",
    "devPred = model.predict(devX)\n",
    "errors = []\n",
    "for indx in range(len(devText)):\n",
    "    if devPred[indx] != devY[indx]:\n",
    "        error = \"Document: \\n {} \\n Predicted: {} \\n Correct: {} \\n ---\".format(\n",
    "            devText[indx],\n",
    "            test['target_names'][devPred[indx]],\n",
    "            test['target_names'][devY[indx]])\n",
    "        errors.append(error)\n",
    "\n",
    "np.random.seed(1)\n",
    "print(\"Random dev error: \\n {} \\n \\n {} \\n \\n{}\".format(\n",
    "        np.random.choice(errors,1),\n",
    "        np.random.choice(errors,1),\n",
    "        np.random.choice(errors,1))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Step 5: Take best model, and report results on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.1938396176314392\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", model.score(testX, testY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
