{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model  import PassiveAggressiveClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Task: News Group Classification\n",
    "\n",
    "Given documents in different news groups (i.e topics):\n",
    "```\n",
    "['alt.atheism',\n",
    " 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x',\n",
    " 'misc.forsale',\n",
    " 'rec.autos',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'sci.crypt',\n",
    " 'sci.electronics',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'soc.religion.christian',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.politics.misc',\n",
    " 'talk.religion.misc']```\n",
    " \n",
    "Train a classifier to predict the topic of a given document. \n",
    "\n",
    "\n",
    "## Step 1: Preprocessing the data\n",
    "To start off, we're going to load the data from sklearn and do some simple preprocessing. We'll remove the headers, footers and quotes in the articles. We'll also do the same preprocessing as before.\n",
    "\n",
    "\n",
    "The sanity check the data, we'll look at a few examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categories = ['alt.atheism',\n",
    " 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'comp.sys.ibm.pc.hardware',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'comp.windows.x',\n",
    " 'misc.forsale',\n",
    " 'rec.autos',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'sci.crypt',\n",
    " 'sci.electronics',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'soc.religion.christian',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.politics.misc',\n",
    " 'talk.religion.misc']\n",
    "\n",
    "full_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "\n",
    "def preprocess_data(data):\n",
    "    processed_data = []\n",
    "    for indx, sample in enumerate(data['data']):\n",
    "        text, label = sample, data['target'][indx]\n",
    "        label_name = data['target_names'][label]\n",
    "        text = re.sub('\\W+', ' ', text).lower().strip()\n",
    "        processed_data.append( (text, label, label_name) )\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "full_train_set = preprocess_data(full_train)\n",
    "train_set = full_train_set[:-5000]\n",
    "dev_set = full_train_set[-5000:]\n",
    "test_set = preprocess_data(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num Train: {}\".format(len(train_set)))\n",
    "print(\"Num Dev: {}\".format(len(dev_set)))\n",
    "print(\"Num Test: {}\".format(len(test_set)))\n",
    "print(\"Example Documents:\")\n",
    "print(train_set[0])\n",
    "print()\n",
    "print(train_set[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering \n",
    "\n",
    "How do we represent a document? This is up to you!\n",
    "Remeber, you can vary the vocabulary size, choose to put ``ngrams``!\n",
    "\n",
    "Remember, we can do this very easily with ```sklearn.feature_extraction.text.CountVectorizer```\n",
    "\n",
    "<img src=\"vectorizer.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract tweets and labels into 2 lists\n",
    "trainText = [t[0] for t in train_set]\n",
    "trainY = [t[1] for t in train_set]\n",
    "\n",
    "devText = [t[0] for t in dev_set]\n",
    "devY = [t[1] for t in dev_set]\n",
    "\n",
    "\n",
    "testText = [t[0] for t in test_set]\n",
    "testY = [t[1] for t in test_set]\n",
    "\n",
    "\n",
    "countVec = ## Intialize your count vectorizer with your arguments\n",
    "\n",
    "\n",
    "# Learn vocabulary from train set\n",
    "countVec.something()\n",
    "\n",
    "# Transform list of review to matrix of bag-of-word vectors\n",
    "trainX = \n",
    "devX = \n",
    "testX = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Train X {}\\n\".format(trainX.shape))\n",
    "print(\"Sample of the vocab:\\n {}\".format(np.random.choice(countVec.get_feature_names(), 20)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Pick a model and experiment\n",
    "\n",
    "Explore various models.\n",
    "\n",
    "I recomment exploring:\n",
    "1) [Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "2) [SVM](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC)\n",
    "\n",
    "And look around the [library](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm) for other options!\n",
    "\n",
    "\n",
    "Remeber, you can explore regulazation strategies as well and change things like `C`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your model\n",
    "model = YourModelClass()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY)\n",
    "\n",
    "\n",
    "print(\"Train Accuracy:\", model.score(trainX, trainY))\n",
    "print(\"Dev Accuracy:\", model.score(devX, devY))\n",
    "print(\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analysis, Debugging the Model\n",
    "To understand how to make the model better, it's important understand what the model is learning, and what it's getting wrong.\n",
    "\n",
    "Recall how we did this for Logistic regression, and feel free to look back at the earlier file if you get stuck. \n",
    "\n",
    "It can be helpful inspect the highest weighted features of the model and look at some examples the model got wrong on the development set. \n",
    "\n",
    "From what you learn, you can go back and change the preprocessing, the feature extraction or play with the model. As you make changes, go back to this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Intepreting The model\")\n",
    "for label in range(20):\n",
    "    coefs = model.coef_[label]\n",
    "    vocab = np.array(countVec.get_feature_names())\n",
    "    num_features = 5\n",
    "\n",
    "    top = np.argpartition(coefs, -num_features)[-num_features:]\n",
    "    # Sort top\n",
    "    top = top[np.argsort(coefs[top])]\n",
    "    s_coef = coefs[top]\n",
    "    scored_vocab = list(zip(vocab[top], s_coef))\n",
    "    print(\"Top weighted features for label {}:\\n \\n {}\\n -- \\n\".format(test_data['target_names'][label], scored_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find erronous dev errors\n",
    "devPred = lr.predict(devX)\n",
    "errors = []\n",
    "for indx in range(len(devText)):\n",
    "    if devPred[indx] != devY[indx]:\n",
    "        error = \"Review: \\n {} \\n Predicted: {} \\n Correct: {} \\n ---\".format(\n",
    "            devText[indx],\n",
    "            devPred[indx],\n",
    "            devY[indx])\n",
    "        errors.append(error)\n",
    "\n",
    "np.random.seed(1)\n",
    "print(\"Random dev error: \\n {} \\n \\n {} \\n \\n{}\".format(\n",
    "        np.random.choice(errors,1),\n",
    "        np.random.choice(errors,1),\n",
    "        np.random.choice(errors,1))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Step 5: Take best model, and report results on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Accuracy:\", model.score(testX, testY))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
